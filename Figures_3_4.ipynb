{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cMMoKz4iPbh2"
   },
   "source": [
    "This code generates **Figure 3 and 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cx46A8G8arzN"
   },
   "outputs": [],
   "source": [
    "## Required Liberaries: \n",
    "#! pip3 install torch \n",
    "#! pip3 install torchvision\n",
    "# and GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4_Ihh6BEOSxd"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M745w4CofR-O"
   },
   "source": [
    "Loading cifar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 100,
     "referenced_widgets": [
      "a2a7156bf8234d028db073003ccd9ff2",
      "83722ebd26984bbfb4fa6d675921b193",
      "7e94fd378fdb4a1fa05d91ba655cfc99",
      "bda069fe05b24f75a0709af8baff7ed0",
      "fbeb6fba1eb144fcb5816d6d907f2aad",
      "b70fa52b38a745859bdf7361c2695d20",
      "fcec701a07974b0c82b530ded44aaceb",
      "df9a07d33fce4f6e958c8ce4706d179a"
     ]
    },
    "id": "GIB-Yw_jOSxk",
    "outputId": "00803f24-62ea-4252-d92d-d0e48cfb6f71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2a7156bf8234d028db073003ccd9ff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ./data/cifar-10-python.tar.gz to ./data/\n"
     ]
    }
   ],
   "source": [
    "batch_size_train = 500\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.CIFAR10('./data/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8Fcfh-eIRygo"
   },
   "outputs": [],
   "source": [
    "# checking the hardware\n",
    "# !nvidia-smi --query-gpu=gpu_name,driver_version,memory.total --format=csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "dPu2ItfLOSxk"
   },
   "outputs": [],
   "source": [
    "### tensor types, to run the code on CPU please update the types \n",
    "dtype = torch.cuda.FloatTensor # CPU -> torch.FloatTensor\n",
    "dtype_labels = torch.cuda.LongTensor # CPU -> torch.cuda.LongTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XJDe-AHUcg4d"
   },
   "source": [
    "Implementation of a multiLayer prectron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TKy2O62cOSxl"
   },
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module): \n",
    "    def __init__(self,layer_num,input_size,width,out_size,bias_on=False,act = None): # act is the activation function\n",
    "        super().__init__()\n",
    "        self.layer_num = layer_num\n",
    "        self.width = width\n",
    "        self.out_size = out_size\n",
    "        self.bias_on = bias_on\n",
    "        self.act = act\n",
    "        self.layers = torch.nn.ModuleList() # contains linear layers \n",
    "        self.layers.append(torch.nn.Linear(input_size,width,bias=bias_on))\n",
    "        for i in range(layer_num-2): \n",
    "              self.layers.append(torch.nn.Linear(width,width,bias=bias_on))\n",
    "        self.layers.append(torch.nn.Linear(width,out_size,bias=bias_on))\n",
    "        self.act = act\n",
    "    def forward(self,x): \n",
    "        out = x\n",
    "        index = 0\n",
    "        for lay in self.layers: # passing input through the layers \n",
    "            index = index +1 \n",
    "            if self.act is not None and index<self.layer_num: \n",
    "                out = self.act(lay(out))\n",
    "            else: \n",
    "                out = lay(out)\n",
    "        return out\n",
    "    def forward_minus(self,x): # skip the output layer\n",
    "        out = x\n",
    "        index = 0\n",
    "        for lay in self.layers:\n",
    "            index = index +1 \n",
    "            if self.act is not None and index<self.layer_num-1: \n",
    "                out = self.act(lay(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AKDWsppecn9c"
   },
   "source": [
    "\n",
    "MLP with batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3h_AkIXccnJT"
   },
   "outputs": [],
   "source": [
    "class BNMLP(torch.nn.Module): \n",
    "    def __init__(self,layer_num,input_size,width,out_size,bias_on=False,act = None): # act is the activation function\n",
    "        super().__init__()\n",
    "        self.layer_num = layer_num\n",
    "        self.width = width\n",
    "        self.out_size = out_size\n",
    "        self.bias_on = bias_on\n",
    "        self.act = act\n",
    "        self.layers = torch.nn.ModuleList() # linear layers\n",
    "        self.layers.append(torch.nn.Linear(input_size,width,bias=bias_on))\n",
    "        for i in range(layer_num-2): \n",
    "              self.layers.append(torch.nn.Linear(width,width,bias=bias_on))\n",
    "        self.layers.append(torch.nn.Linear(width,out_size,bias=bias_on))\n",
    "        self.act = act\n",
    "        self.bns = torch.nn.ModuleList() # batch normalization layers\n",
    "        for i in range(layer_num-1): \n",
    "              self.bns.append(torch.nn.BatchNorm1d(num_features=width)) # for MLPs we use 1d batch normalization\n",
    "    def forward(self,x): \n",
    "        out = x\n",
    "        for i in range(self.layer_num-1):\n",
    "            if self.act is not None: \n",
    "                out = self.act(self.bns[i](self.layers[i](out)))\n",
    "            else: \n",
    "                out = self.bns[i](self.layers[i](out))\n",
    "       \n",
    "        out = self.layers[self.layer_num-1](out)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "667Q9IWycugh"
   },
   "source": [
    "Here, we implement xavier's initialization of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8tOv3c55OSxl"
   },
   "outputs": [],
   "source": [
    "layer_num = 50\n",
    "out_size =10 \n",
    "input_size = 3*32*32\n",
    "width = batch_size_train\n",
    "net = MLP(layer_num, input_size,width,out_size)\n",
    "net = net.cuda()\n",
    "def xavier_init(m): # xavier initialization \n",
    "    if isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight, gain=torch.nn.init.calculate_gain('relu'))\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0)\n",
    "def kaiming_init(m):\n",
    "    if isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5NpDsvbarBf"
   },
   "source": [
    "The following functions implements the iterative initialization. Let $H_\\ell \\in R^{d \\times n}$ denotes hidden representations in layer $\\ell$. we use SVD decompostion $H_\\ell = U_\\ell \\Sigma_\\ell V_\\ell^\\top$ to initialize weights in layer $\\ell$ as \n",
    "$$W_\\ell = \\frac{1}{\\| \\Sigma^{1/2} \\|_F } V'_\\ell \\Sigma_\\ell^{1/2} U_\\ell^\\top$$ \n",
    "where $V'_\\ell$ is a slice of $V_\\ell$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "nG4FevBCOSxm"
   },
   "outputs": [],
   "source": [
    "def improved_init(net, width):\n",
    "   # picking a large mini batch of inputs\n",
    "    batch_size_train = 3*width\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "      torchvision.datasets.CIFAR10('./data/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "                             ])),\n",
    "     batch_size=batch_size_train, shuffle=True)\n",
    "    examples = enumerate(loader)\n",
    "    batch_idx, (images, example_targets) = next(examples)\n",
    "    H0 = images.view(-1,3*32*32).type(dtype)\n",
    "   \n",
    "    H = H0\n",
    "    gamma = 0.1\n",
    "    layer_num = net.layer_num\n",
    "    # passing the input and compute the hidden representation and weights iteratively  \n",
    "    for i in range(layer_num-1):\n",
    "        if i>0: \n",
    "            Hdata = H.data\n",
    "            u,s, v = torch.svd(Hdata) # svd computation \n",
    "            wd = net.layers[i].weight.data.size(0)\n",
    "            w = u[0:wd,0:wd].mm(torch.diag(1/torch.pow(s[0:wd],1))).mm(v.t()[0:wd,:]) # weight initialization\n",
    "            net.layers[i].weight.data = w\n",
    "            net.layers[i].weight.data = w \n",
    "            net.layers[i].weight.data = net.layers[i].weight.data/torch.norm(net.layers[i](H)) # normalization factor\n",
    "        if net.act is not None:\n",
    "            H = net.act(net.layers[i](H))\n",
    "        else:\n",
    "            H = net.layers[i](H)\n",
    "   \n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "5JJZoiWTue92"
   },
   "outputs": [],
   "source": [
    "def compute_orthogonality_gap(net):\n",
    "  loader = torch.utils.data.DataLoader(\n",
    "      torchvision.datasets.CIFAR10('./data/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "                             ])),\n",
    "     batch_size=batch_size_train, shuffle=True)\n",
    "  avg_gap = 0\n",
    "  index = 0 \n",
    "  for x,y in loader: \n",
    "    index += 1\n",
    "    x = x.type(dtype)\n",
    "    y = y.type(dtype_labels)\n",
    "    out = net.forward(torch.flatten(x,1))\n",
    "    u1,s1,v1 = torch.svd(out.data)\n",
    "    s1 = s1/torch.norm(s1)\n",
    "    s2 = torch.tensor(np.ones(s1.size(0))/math.sqrt(s1.size(0))).type(dtype)\n",
    "    avg_gap += torch.norm(s1-s2)\n",
    "  avg_gap = avg_gap/index\n",
    "  print('average of the orthogonality gap is ',avg_gap)\n",
    "  return avg_gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "rmp297Vt8B4s"
   },
   "outputs": [],
   "source": [
    "def train(net,train_loader,epochs_num = 10,stepsize=0.01):\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(net.parameters(),lr=stepsize)\n",
    "    conv = []\n",
    "    gaps = []\n",
    "    itrs = []\n",
    "    for i in range(epochs_num):\n",
    "        current_loss = 0 \n",
    "        r_size = 0\n",
    "        for x,y in train_loader: \n",
    "            x = x.type(dtype)\n",
    "            y = y.type(dtype_labels)\n",
    "            r_size += x.size(0)\n",
    "            optimizer.zero_grad()\n",
    "            predy = net(torch.flatten(x,1))\n",
    "            loss = loss_function(predy,y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            current_loss += loss.item()*batch_size_train\n",
    "        if i % 5 == 0:\n",
    "          gaps.append(compute_orthogonality_gap(net))   \n",
    "          conv.append(current_loss/r_size)\n",
    "          itrs.append(i+1)\n",
    "          print(current_loss/r_size) \n",
    "    return conv,gaps,itrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JLk-Gv2woS8S"
   },
   "outputs": [],
   "source": [
    "# computing the decay in the orthogonality gap for the iterative initialization ## in figure 3.b \n",
    "ACTIVE = torch.nn.functional.relu\n",
    "convs =[] # convergence rate\n",
    "gaps = [] # orthogonality gap during training\n",
    "repeat = 5\n",
    "for i in range(repeat):\n",
    "  mynet = MLP(20, input_size,1000,out_size,act=torch.nn.functional.relu,bias_on = False)\n",
    "  mynet = mynet.cuda()\n",
    "  mynet.apply(xavier_init)\n",
    "  conv, gap,itrs = train(mynet,train_loader,epochs_num = 50)\n",
    "  convs.append(conv)\n",
    "  gaps.append(gap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBptIV3EjdPN"
   },
   "source": [
    "The convergence for different initialization methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3nF9PijG9iVY"
   },
   "outputs": [],
   "source": [
    "# Figures 3.a, 4.a, and 4.b\n",
    "layers = [15,30,45,60,75]\n",
    "bias_on = False\n",
    "width = 800\n",
    "epochs = 30\n",
    "repeat = 4\n",
    "ACTIVE = torch.nn.functional.relu\n",
    "ouresults = np.zeros((len(layers),epochs,repeat))\n",
    "xavir_result = np.zeros((len(layers),epochs,repeat))\n",
    "for j in range(repeat):\n",
    "  for i in range(len(layers)): \n",
    "      layer_num = layers[i]\n",
    "      mynet = MLP(layer_num, input_size,width,out_size,act=ACTIVE,bias_on = bias_on)\n",
    "      mynet = mynet.cuda()\n",
    "      mynet.apply(xavier_init)\n",
    "      mynet = improved_init(mynet,width)\n",
    "      print(i,'our initialization -----')\n",
    "      res = train(mynet,train_loader,epochs_num = epochs)\n",
    "      ouresults[i,:,j] = res[0]\n",
    "      print(i,'xavier initialization----')\n",
    "      netx = MLP(layer_num, input_size,width,out_size,act=ACTIVE,bias_on = bias_on)\n",
    "      netx = netx.cuda()\n",
    "      netx = netx.apply(xavier_init)\n",
    "      result_xavier =  train(netx,train_loader,epochs_num = epochs)\n",
    "      xavir_result[i,:,j] =result_xavier[0]\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BN_NIPS21_Figures_3_4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "7e94fd378fdb4a1fa05d91ba655cfc99": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b70fa52b38a745859bdf7361c2695d20",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fbeb6fba1eb144fcb5816d6d907f2aad",
      "value": 170498071
     }
    },
    "83722ebd26984bbfb4fa6d675921b193": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2a7156bf8234d028db073003ccd9ff2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7e94fd378fdb4a1fa05d91ba655cfc99",
       "IPY_MODEL_bda069fe05b24f75a0709af8baff7ed0"
      ],
      "layout": "IPY_MODEL_83722ebd26984bbfb4fa6d675921b193"
     }
    },
    "b70fa52b38a745859bdf7361c2695d20": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bda069fe05b24f75a0709af8baff7ed0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df9a07d33fce4f6e958c8ce4706d179a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_fcec701a07974b0c82b530ded44aaceb",
      "value": " 170499072/? [10:33&lt;00:00, 269158.70it/s]"
     }
    },
    "df9a07d33fce4f6e958c8ce4706d179a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fbeb6fba1eb144fcb5816d6d907f2aad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "fcec701a07974b0c82b530ded44aaceb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
